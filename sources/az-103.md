# Exam Ref AZ-103 Microsoft Azure Administrator, by Michael Washam, Jonathan Tuliani, and Scott Hoag

> - [x] 1.1: Manage Azure Subscriptions
> - [x] 1.1a: Assigning administrator permissions
> - [ ] 1.1b: Configure cost center quotas and tagging
> - [ ] 1.1c: Configure Azure subscription policies
> - [ ] 1.2: Analyze resource utilization and consumption
> - [ ] 1.2a: Configure diagnostic settings on resources
> - [ ] 1.2b: Create and test alerts
> - [ ] 1.2c: Analyze alerts across subscriptions
> - [ ] 1.2d: Analyze metrics across subscriptions
> - [ ] 1.2e: Utilize log search query functions
> - [ ] 1.2f: Monitor for unused resources
> - [ ] 1.2g: Monitor and report spend
> - [ ] 1.3: Manage resource groups
> - [ ] 1.3a: Use Azure policies for resource groups
> - [ ] 1.3b: Configure resource logs
> - [ ] 1.3c: Implement and set tagging on resource groups
> - [ ] 1.3d: Move resources across resource groups
> - [ ] 1.3e: Remove resource groups
> - [ ] 1.4: Manage role-based access control (RBAC)
> - [ ] 1.4a: Role-Based Access Control
> - [ ] 1.4b: How RBAC works
> - [ ] 1.4c: Implementing RBAC using the portal
> - [ ] 2.1: Create and configure storage accounts
> - [ ] 2.1a: Create and configure a storage account
> - [ ] 2.1b: Configure network access to the storage account
> - [ ] 2.1c: Manage access keys
> - [ ] 2.1d: Generate a shared access signature
> - [ ] 2.1e: Monitor activity log by using Log Analytics
> - [ ] 2.1f: Implement Azure storage replication
> - [ ] 2.2: Import and export data to Azure
> - [ ] 2.2a: Configure and use Azure blob storage
> - [ ] 2.2b: Create export from Azure job
> - [ ] 2.2c: Create import into Azure job
> - [ ] 2.2d: Use Azure Data Box
> - [ ] 2.2e: Configure Azure content delivery network (CDN) endpoints
> - [ ] 2.3: Configure Azure files
> - [ ] 2.3a: Using the Azure File Service
> - [ ] 2.3b: Create Azure File Sync service
> - [ ] 2.3c: Create Azure sync group
> - [ ] 2.3d: Troubleshoot Azure File Sync
> - [ ] 2.4: Implement Azure Backup
> - [ ] 2.4a: Create Recovery Services Vault
> - [ ] 2.4b: Backup and restore data
> - [ ] 2.4c: Configure and review backup reports
> - [ ] 2.4d: Create and configure backup policy
> - [ ] 3.1: Create and configure a VM for Windows and Linux
> - [ ] 3.1a: Creating virtual machines
> - [ ] 3.1b: Configuring high availability
> - [ ] 3.1c: Configure virtual machine size
> - [ ] 3.1d: Authentication options
> - [ ] 3.1e: Configure storage
> - [ ] 3.1f: Configure networking
> - [ ] 3.1g: Configure monitoring
> - [ ] 3.1h: Deploy and configure scale sets
> - [ ] 3.2: Automate deployment of VMs
> - [ ] 3.2a: Deploy Windows and Linux VMs
> - [ ] 3.2b: Configure VHD template
> - [ ] 3.2c: Deploy from template
> - [ ] 3.2d: Modify Azure Resource Manager (ARM) template
> - [ ] 3.2e: Save a deployment as an ARM Template
> - [ ] 3.2f: Configure location of new VMs
> - [ ] 3.3: MAnage Azure VM
> - [ ] 3.3a: Add data disks
> - [ ] 3.3b: Add network interfaces
> - [ ] 3.3c: Manage VM sizes
> - [ ] 3.3d: Move VMs from one resource group to another
> - [ ] 3.3e: Redeploy VMs
> - [ ] 3.3f: Automate configuration management
> - [ ] 3.4: Manage VM Backups
> - [ ] 3.4a: Add data disks
> - [ ] 3.4b: Add network interfaces
> - [ ] 3.4c: Manage VM sizes
> - [ ] 3.4d: Move VMs from one resource group to another
> - [ ] 3.4e: Redeploy VMs
> - [ ] 3.4f: Automate configuration management
> - [ ] 4.1: Implement and manage virtual networking
> - [ ] 4.1a: Create and configure a virtual network and subnets
> - [ ] 4.1b: Configure private IP addresses and network interfaces
> - [ ] 4.1c: Create and configure public IP addresses
> - [ ] 4.1d: Configure network routes
> - [ ] 4.2: Create connectivity between virtual networks
> - [ ] 4.2a: Create and configure VNet peering
> - [ ] 4.2b: Create a virtual network gateway and configure VNET to VNET connectivity
> - [ ] 4.2c: Verify virtual network connectivity
> - [ ] 4.3: Configure name resolution
> - [ ] 4.3a: Configure Azure DNS
> - [ ] 4.3b: Configure custom DNS settings
> - [ ] 4.3c: Configure private DNS zones
> - [ ] 4.4: Create and configure a network security group
> - [ ] 4.4a: Create security rules
> - [ ] 4.4b: Associate NSG to a subnet or network interface
> - [ ] 4.4c: Identify required ports
> - [ ] 4.4d: Evaluate effective security rules
> - [ ] 4.5: Implement Azure load balancer
> - [ ] 4.5a: Configure internal load balancer, load balancing rules, and public load balancer
> - [ ] 4.5b: Troubleshoot load balancing
> - [ ] 4.6: Monitor and troubleshoot virtual networking
> - [ ] 4.6a: Monitor on-premises connectivity
> - [ ] 4.6b: Use network resource monitoring
> - [ ] 4.6c: Use Network Watcher
> - [ ] 4.6d: Troubleshoot external networking
> - [ ] 4.6e: Troubleshoot virtual network connectivity
> - [ ] 4.7: Integrate on-premises network with Azure virtual network
> - [ ] 4.7a: Create and configure Azure VPN Gateway
> - [ ] 4.7b: Create and configure site-to-site VPN
> - [ ] 4.7c: Configure ExpressRoute
> - [ ] 4.7d: Verify and troubleshoot on-premises connectivity
> - [ ] 5.1: Manage Azure Active Directory
> - [ ] 5.1a: Add custom domains
> - [ ] 5.1b: Configure Azure AD Identity Protection, Azure AD Join, and Enterprise State Roaming
> - [ ] 5.1c: Configure self-service password reset
> - [ ] 5.1d: Implement conditional access policies
> - [ ] 5.1e: Manage multiple directories
> - [ ] 5.1f: Perform an access review
> - [ ] 5.2: Manage Azure AD Objects
> - [ ] 5.2a: Create users and groups
> - [ ] 5.2b: Manage user and group properties
> - [ ] 5.2c: Manage device settings
> - [ ] 5.2d: Perform bulk user updates
> - [ ] 5.3: Implement and manage hybrid identities
> - [ ] 5.3a: Install and configure Azure AD Connect
> - [ ] 5.3b: Configure federation and single sign-on
> - [ ] 5.3c: Manage password sync and writeback
> - [ ] 5.4: Implement multi-factor authentication
> - [ ] 5.4a: Multi-Factor Authentication
> - [ ] 5.4b: Azure MFA advanced features

## Tasks 
#### Assign an RBAC role (Portal)
> AZ-103: 1.1a.1 (p. 4)
To assign an RBAC role to a subscription, open the __Subscription__, then the __Access Control (IAM)__ blades, then click __Add Role Assignment__. This will open a dialog box where you can select a __Role__ (e.g. Owner) then __Select__ a target principal.
#### Configure resource quotas
> AZ-103: 1.1b.1 (p. 9)
To view resource quotas for a subscription, go to the subscription in Azure Portal and open the __Usage + quotas__ blade. From there you can select resources and then click the __Request Increase__ button.

PowerShell commands used with resource quotas:
  - `Get-AzVMUsage`: view current usage of vCPU quotas
  - `Get-AzStorageUsage`: view current usage of storage service
#### Configure cost center quotas
> AZ-103: 1.1b.2 (p. 10)
Budgets can be viewed and administered in the __Cost Management + Billing__ blade. Users must be at least Reader to a subscription to view, and Contributor to create and manage, budgets. Specialized roles that grant access to Cost Management include
  - __Cost Management contributor__
  - __Cost Management reader__

To create a budget, open __Cost Management + Billing__, then __Subscriptions__, select a subscription, then click __Budgets__. Then click __+ Add__, which produces a Create budget blade. The created budget can be seen in the __Budgets__ blade.

PowerShell commands used with budgets:
  - `Get-AzResourceGroup` retrieve Resource Group object
  - `Set-AzResourceGroup` apply a tag to a resource group with __no preexisting tags__
  - `.Tags` method that retrieves Tag collection from a resource group
  - `.Add()` method used to add tags to a resource group that __already has__ tags.
#### Create a storage container (PowerShell)
> AZ-103: 2.2a.1 (p. 132)
`New-AzStorageContainer` require a storage context to be set, specifying the storage account anme and authentication credentials.

```powershell
PS C:\> $storageKey = Get-AzStorageAccountKey
>>  -Name $storageAccount `
>>  -ResourceGroupName $resourceGroup

PS C:\> $context = New-AzStorageContext `
>>  -StorageAccountName $storageAccount `
>>  -storageAccountKey $storageKey.Value[0]

PS C:\> Set-AzCurrentStorageAccount -Context $context

PS C:\> New-AzStorageContainer `
>>  -Name $container
>>  -Permission Off
```
## Contents
### 1.1: Manage Azure Subscriptions
### 1.1a: Assign administrator permissions
Azure methods of administering access to resources can be divided into two groups
  1. __Classic__ subscription administration roles 
    - Account Administrator
    - Service Administrator
    - Co-Administrator
  2. __Role-Based Access Controls (RBAC)__

Classic subscription administrators have full access to a subcription. They can access resources through Azure Portal, ARM APIs (PowerShell and CLI), and classic deployment model APIs. By default, the account that is used to sign up for a subscription is automatically set as both __Account Administrator__ and __Service Administrator__. There can only be one Account Administrator per account and only 1 Service Administrator per subscription. __Co-Administrators__ have the same access as Service Administrators, and there can be 200 of them per subscription, but cannot change the association of subscriptions to directories.

Current assignments for classic admins can be seen in the __Properties blade__ of a subscription in Azure Portal.
Co-Administrator assignments can be added by opening the __Access Control (IAM)__ blade of a subscription, then clicking the __Add co-administrator__ button. 

RBAC roles are supported only by Azure Portal and the ARM APIs. Access is applied to a __scope__, which includes subscriptions, resource groups, or resources. Azure Policy can be applied at various __scopes__. For example, a policy applied to a subscription is said to be at the "subscription scope". Policy can also be applied to Management Groups, which is an additional scope above subscription. In this way, several subscriptions can inherit a single policy through a Management Group.

There is a built-in role named __Resource Policy Contributor__, which includes access to most Policy operations and should be considered privileged.

RBAC roles can be used to grant rights to 2 types of principals:
  1. __User principal__: identity associated with a user or group of users.
  2. __Service principal__: identity associated with an application.

There are more than __70__ built-in RBAC roles, allowing fine-grained access management, but __4__ of them are foundational:
  1. __Owner__ has full access to all resources and __can__ delegate access. Service Administrator and Co-Administrators are assigned this role at the subscription scope.
  2. __Contributor__ can create and manage all resources, but __cannot__ delegate access.
  3. __Reader__ can view resources.
  4. __User Access Administrator__ only manages user access to resources.

RBAC roles can also be applied to a subscription through __Management Groups__, which represent the recommended practice for ensuring consistent application of tenant-wide security. Management groups form a hierarchy where each child inherits policy from its single parent while having additional controls. There is a singel Management Group at the root of the hierarchy, associated with the Azure AD tenant (which is associated, in turn, with a subscription) that cannot be moved or deleted. 

> Task: Assign an RBAC role (Portal): 1.1a.1 (p. 4)
### 1.1b: Configure cost center quotas and tagging
There are 2 types of quota that apply to subscriptions:
  1. __Resource quotas__ trigger alarms when resource creation and consumption hit a threshold. These are not to be confused with __resource limits__ which can stop resources from being created, whereas quotas can not.
  2. __Spending quotas__ trigger alarms when spending has reached a thresthold.

These are facilitated through the use of tags, which allow categorization of resource groups and resources.

> Task: Configure resource quotas: 1.1b.1 (p.9)
> Task: Configure cost center quotas: 1.1b.2 (p.10)
> Task: Tag a resource group that has no
#### Tag a resource group that already had been tagged (PowerShell)
> AZ-103: 1.1b.3 (p. 14)
```powershell
$tags = (Get-AzResourceGroup -Name hrgroup).Tags
$tags.Add("Owner","user@contoso.com")
Set-AzResourceGroup -Tag $tags -Name hrgroup
```

Using the `Add()` method
```powershell
$r = Get-AzResource -ResourceName hrvm1 -ResourceGroupName hrgroup
$r.Tags.Add("Owner","user@contoso.com")
Set-AzResource -Tag $r.Tags -ResourceId $r.ResourceId -Force
```

#### Tag a resource-group that has not already been tagged (PowerShell)
```powershell
$r = Get-AzResource -ResourceName hrvm1 -ResourceGroupName hrgroup
Set-AzResource -Tag @{ CostCode="1001"; Environment="Production" } -ResourceId
$r.ResourceId -Force
```

#### Configure Azure subscription policies
__Azure Policy__ is a service that can create, assign, and manage policies to enforce governance. Where Azure RBAC controls individual user and group access at specific scopes, Azure Policy allows environment to be governed for all users at a specified scope regardless of RBAC assignment. RBAC is default deny with explicit allow, whereas policy is default allow with explicit deny. Policy definitions, authored in JSON, implement policy by describing desired behavior for Azure resources when they are created or updated.

Azure Policy definition schema elements:
  - `mode`: which resources are scoped
    - `all`: both resource groups and all resources (default for policies defined in Portal)
    - `indexed`: only resource types that support tags and location (not all of them do)
  - `policyRule`
    - `if` block defines one or more conditions with logical operators
      - `field`: `type` represents type of resource being created based on the resource provider it belongs to
    - `then`: action to be taken
      - `effect` can have several values
        - `deny` generate an event in the activity log and fail the request
        - `audit` generate a warning event in the activity log but do not fail the request
        - `append` adds defined set of fields to the request
        - `auditifnotexists` enables auditing if a resource doesn't exist
        - `deployifnotexists` deploy a resource if it doesn't already exist
        - `disabled` don't evaluate resources for compliance to policy
      - `details`
  - `parameters`: make policy definitions reusable
    - name: i.e. `listOfAllowedSKUs`
      - `type` can be `string` or `array`
      - `metadata` is used by the Portal to display information for parameters; includes sub-properties `displayName`, `description`, and optionally `strongType`. `strongType` will produce a context menu of selections available populated by resources matching the value (i.e. if `vmSKUs` is the value it will produce a list of VMs when applying the policy)
      - `defaultValue`
      - `allowedValues`

#### Create a policy definition (Portal)
Open __All Services__, then __Policy__, then the __Definitions__ blade. Both builtin and custom policies can be managed here.

#### Register resource provider in subscription (Azure CLI)
Az CLI can be used to register the `Microsoft.PolicyInsights` resource provider is registered in the target subscription, a prerequisite for policy creation:
```bash
az provider register --namespace 'Microsoft.PolicyInsights'
```

#### Define a policy (Azure CLI)
```bash
$ az policy definition create \
> --name 'allowedVMs' \
> --description 'Only allow virtual machines in the defined SKUs' 
> --mode ALL \
> --rules '{...}' \
> --params '{...}'
```

#### Apply policy to a scope (Azure CLI)
```bash
$ az policy assignment create \
> --policy allowedVMs \
> --name 'deny-non-compliant-vms' \
> --scope '/subscriptions/<Subscription ID>' -p
```

#### Delete policy assignment (Azure CLI)
```bash
$ az policy assignment delete \
> --name deny-non-compliant-vms
```

PowerShell commands:
  - `New-AzPolicyDefinition` add new definition
    - `-Name`
    - `-DisplayName`
    - `-Policy` takes the filename of the actual policy definition
  - `New-AzPolicyAssignment` make a policy assignment
    - `-Name`
    - `-DisplayName`
    - `-Scope`
    - `-PolicyDefinition`
    - `-PolicyParameter`
  - `Remove-AzPolicyAssignment` remove a policy assignment
    - `-Id`
  - `Remove-AzPolicyDefinition` remove a policy definition
    - `-Id`
### 1.2: Analyze resource utilization
A robust monitoring strategy implementing proactive notifications helps to increase uptime and optimize performance. Azure offers __Azure Monitor__ and __Azure Advisor__.
  - __Azure Monitor__ provides a single point of contact for both metrics and logs. 
  - __Azure Advisor__ is a free, personalized guide to Azure best practices that provides recommendations to help you optimize resources.

Distinction between __metrics__ and __logs__:
  - Metrics are strictly numerical, while logs can be numerical or textual
  - Metrics are continuously collected, while log entries are less predictable

Azure Monitor can create __alert rules__ that are built on target resources or resource type and that proactively notify you of the health of resources and can also leverage action groups that automate actions to take in certain conditions.
### 1.2a: Configure diagnostic settings on resources
__Diagnostics logs__ are a type of log data that can be configured to send data to other locations, such as a Storage account or __Log Analytics__ workspace. Diagnostics logs have to be enabled for each resource to be monitored. Settings can be configured through Portal, ARM APIs, or the Azure Monitor REST APIs

To enable diagnostics logs through Portal, browse to the resource itself. Alternatively, open __Azure Monitor__ and then the __Diagnostics Settings__ blade. From there you can view all eligible resouce types and view status of log collection. __Azure Activity logs__ are another type of data that is surfaced at the subscription level, but lacks resource-level detail.

#### Enable diagnostics log collection with a storage account (PowerShell)
```powershell
PS C:\> $resource = Get-AzResource `
>>   -Name <resourceName> `
>>   -ResourceGroupName <resourceGroupName>
PS C:\> $storage = Get-AzResource `
>>   -Name <resourceName> `
>>   -ResourceGroupName <resourceGroupName>
PS C:\> Set-AzDiagnosticSetting `
>>   -ResourceId $resource.ResourceId `
>>   -StorageAccountId $storage.ResourceId `
>>   -Enabled $true
```

#### Enable diagnostics log collection with a storage account (CLI)
```bash
$ az monitor diagnostic-settings create \
> --name <diagnosticName> \
> --storage-account <storageId> \
> --resource <resouceId> \
> --resouce-group <resourceGroup> \
> --logs '[ {
  "category": <categoryName>,
  "enabled": true,
  "retentionPolicy": {
    "days": <numberOfDays>,
    "enabled": true } } ] '
```

#### Enable diagnostics log streaming to an Event Hub (PowerShell)
```powershell
PS C:\> $rule = Get-AzServiceBusRule -ResourceGroup <resourceGroupName> `
>> -Namespace <namespace> `
>> -Topic <topic> `
>> -Subscription <subscription> `
>> -Name <ruleName> 
PS C:\> Set-AzDiagnosticSetting `
>> -ResourceId $resource.ResourceId `
>> -ServiceBusRuleId $rule.Id `
>> -Enabled $true
```

#### Enable diagnostics log streaming to an Event Hub (CLI)
```bash
$ az monitor diagnostic-settings create \
> --name <diagnosticName> \
> --event-hub-rule <eventHubRuleId> \
> --resource <targetResourceId> \
> --logs '[{
  "category": <categoryName>,
  "enabled": true }]'
```

#### Enable diagnostics logs collection in a Log Analytics workspace (PowerShell)
```powershell
PS C:\> $workspace = Get-AzOperationalInsightsWorkspace `
>> -Name <workspaceName> `
>> -ResourceGroupName <resourceGroupName> 
PS C:\> Set-AzDiagnosticSetting `
>> -ResourceId $resource.ResourceId `
>> -WorkspaceId $workspace.ResourceId `
>> -Enabled $true
```

#### Enable diagnostics logs collection in a Log Analytics workspace (CLI)
```bash
$ az monitor diagnostic-settings create \
> --name <diagnosticName> \
> --workspace <logAnalyticsName> \
> --resource <resourceId> \
> --resouce-group <logAnalysticsWorkspaceResourceGroup> \
> --logs '[{
  "category": <categoryName>,
  "enabled": true }]'
```
### 1.2b: Create and test alerts

> __Azure Monitor__ brings a unified alerting experience to Azure, with a single pane of glass for interacting with metrics, the __Activity Log__, __Log Analytics__, service and resource health and service-specific insights.

Alerts have many notification options, including email, SMS, mobile app, voice, and integration with automation. Alerts are centered on but distinct from __alert rules__.

Alert rules contain:
  - **Name and description**
  - __Target resource__, an Azure resource that generates signals, defines the scope and signals available for the alert.
  - __Signal__ (i.e. metric or Activity Log) emitted by target resource. Signals are of 3 types: 
    1. Metrics
    2. Log search queries 
    3. Activity logs
  - __Conditional logic__ for alert combines the signal and a logical test to trigger alert.
  - __Action Group__ determines what will happen when the alert is trigged. Action groups are themselves resources, and thus located in a subscription and resource group, and have:
    - **Name**
    - **Short name** is used to identify the Action Group in emails and notifications and is limited to 12 characters
    - **Actions** define the configuration for a specific action type. Available types includ:
      - Email/SMS/Push/Voice
      - Azure Function
      - Logic App
      - Webhook
      - ITSM
      - Automation Runbook
  - Severity (0-4)

#### Create an alert rule (Portal)
1. **Alerts**
2. **New Alert Rule** button
### 1.2c: Analyze alerts across subscriptions 
Alerts can have 3 states:
  - **New** and not reviewed
  - **Acknowledged** issue is being actioned by an admin
  - **Closed** issue that generated the alerts has been resolved and the alert has been marked as closed

These are changed by admins, not by the Azure platform.

### 1.2d: Analyze metrics across subscriptions 
Metrics are the numerical values output by resources and services within Azure. They are collected a 1-minute intervals, identified by a metric name and namespace (category). Metrics can be one-dimensional or have up to 10 dimensions, and have the following properties:
  - **Time** the value was collected
  - **Type** of measurement made
  - **Resource** associated with value
  - **Value**

Metrics can be stored in:
  - Azure Monitor for 93 days
  - __Log Analytics__ for 2 years
  - Storage account, where they are treated according to the retention policy and storage limits of the account.

### 1.2e Utilize log search query functions 
Comparison of logs and metrics

                      | Logs                        | Metrics
:---                  | :---                        | :---
**Retention**         | Stored in Log Analytics (2 years) | Stored in Monitor for 93 days, but metrics can be sent to Log Analytics and Storage accounts as well
**Properties**        | Varying properties for each log, with support for rich data types such as date and time | Fixed set of properties (or attributes): time, type, resource, value, and (optionally) dimensions.
**Data availability** | Triggered by an event, requiring time to process before they are available for querying | Gathered at intervals and available for immediate querying.

**Log Analytics workspace** is where logs are collected and aggregated. The logs can be queried through Log Analytics or Monitor. Because a workspace is a resource, RBAC can be applied to control access to it. 
A workspace requires:
  - **Name** for the workspace
  - **Subscription** associated with it
  - **Resource group**
  - **Location**
  - **Pricing tier selection**

#### Create a new Log Analytics workspace (PowerShell)
A new workspace can be configured through the Log Analytics blade, or through APIs using a Resource Manager template.
```powershell
PS C:\> $params = @{
>> workspaceName = "ExampleLA"
>> location = "eastus"
>> sku = "PerGB2018"
}
PS C:\> New-AzResourceGroup `
>> -Name ExamRefRG `
>> -Location "East US"
PS C:\> New-AzResourceGroupDeployment `
>> -ResourceGroupName ExamRefRG `
>> -TemplateFile 'azuredeploy.json' `
>> -TemplateParameterObject $params `
>> -Verbose
```

Once a workspace is configured, machines can be onboarded. In order to report telemetry to Log Analytics, they must be running the Azure Log Analytics (OMS) agent, which needs to have port 443 open for inbound and outbound traffic on telemetered machines.

Log Analytics uses the __Kusto__ query language. Kusto queries use the pipe character to separate commands, always begin with a scope, are case-sensitive, and generate read-only requests so log entries are only deleted based on retention policy.

### 1.2f Monitor for unused resources 
__Azure Advisor__ offers personalized recommendations across 4 domains:
  - High availability
  - Security
  - Performance
  - Cost

Virtual machines can be one of the most expensive resources in a cloud implementation, and there are several ways to reduce their cost
  - Deallocate compute when not needed
  - Delete unused virtual machines and allocate them only on demand
  - Right-size VMs so that you don't overuse resources

Advisor can also identify
  - ExpressRoute circuits that have been "Not Provisioned" for more than 30 days
  - Gateways that have been idle for more than 90 days

### 1.2g Monitor and report spend 
Customers on an __Enterprise Agreement__ can add up-front commitments to Azure then be billed annually. If the committed spend is exceeded, the overage is billed at the same EA rate. EA customers can create spending quotas and set notification thresholds through the EA Portal.

3 portals used to manage Azure subscriptions
  1. EA Portal (ea.azure.com) available only to customers with an Enterprise Agreement
  2. Account Portal
  3. Azure Portal, includes Azure Cost Management

### 1.3: Manage resource groups
A resource group may not be nested within another, and although a resource may only be associated with a single resource group at a time, they can be moved around at will and resources from different resource groups can interact with one another. Resource groups can also be used to scop both access control and policy. Finally, a resource group is created in a location, which specified where its metadata is stored.

Automating the creationg and configuration of resources is recommended for consistent environments. To do this, use __Resource Manager templates__, which are JSON files that define the infrastructure and configuration of Azure resources.

Resource Manager template required properties:
  - $schema
  - `contentVersion`
  - `resources`
Optional properties:
  - `parameters`
  - `variables`
  - `functions`
  - `outputs`

#### Delete a resource group (PowerShell)
```powershell
PS C:\> Remove-AzResourceGroup -Name "hrgroup"
```

#### Delete a resource group without confirmation (PowerShell)
```powershell
PS C:\> Remove-AzResourceGroup -Name "hrgroup" -Force
```

#### Delete a resource group (CLI)
```bash
$ az group delete --name hrgroup
```

#### Delete a resource group without confirmation (CLI)
```bash
$ az group delete --name hrgroup --yes
```


### 2.1: Create and configure storage accounts
### 2.1a: Create and configure a storage account
4 storage services provided within each storage account:
  1. **Blobs** provides a highly scalable service for storing arbitrary data objects, such as text or binary data
  2. **Tables** provides a NoSQL-style store for storing structured data. Tables in Azure storage do not require a fixed schema, thus different entries in the same table can have different fields
  3. **Queues** provides reliable message queueing between application components
  4. **Files** provides managed file shares that can be used by VMs or on-premises servers

3 types of storage blobs
  1. Block blobs
  2. Append blobs
  3. Page blobs: used to store VHD files when deploying unmanaged disks (not recommended)

Options that must be selected when creating a storage account:
  - Performance tier
  - Account kind
  - Replication option
  - Access tier

Performance tiers:
  1. **Standard** supports all storage services and uses magnetic disks to provide cost-efficient and reliable storage
  2. **Premium** only supports page blobs with the locally-redundant (LRS) replication option, uses high-performance SSD disks

Replication options:
  - **Locally-redundant storage (LRS)** makes 3 local sychronous (within a single datacenter) copies 
  - **Zone-redundant storage (ZRS)** makes 3 synchronous copies across multiple availability zones; available for general-purpose v2 storage accounts at **Standard** performance tier only.
  - **Geographically-redundant storage (GRS)** makes 3 local synchronous copies plus 3 additional asynchronous copies (typically within 15 minutes, but no SLA) to a second data center far away from the primary region
  - **Read-access geographically redundant storage (RA-GRS)** makes 3 local synchronous copies plus 3 additional asynchronous copies to a second data center far away from the primary region, which has only read-only access

Blob storage access tiers
  1. **Hot** blob storage access tier optimized for the frequent access of objects in the storage account
  2. **Cool** blob storage access tier optimized for storing large amounts of data that is infrequently accessed and stored for at least 30 days
  3. **Archive** blob storage access tier designed for long-term storage of infrequently-used data that can tolerate several hours of retrieval latency, remaining in the Archive tier for at least 180 days. It is stored offline and can take up to 15 hours for it to be "rehydrated" to the Cool or Hot tier before it can be accessed.
  4. **Premium** providing high-performance access for frequently-used data on SSD, only available from the **Block Blob** storage account type.

Account kinds:
  1. General-purpose V2: only kind to support ZRS
  2. General-purpose V1: does not support various access tiers.
  3. Blob storage: specialized storage account used to store block and append blobs

Both Blob and StorageV1 can be upgraded to StorageV2, a process which is irreversible. 

### Storage creation command options

Description                 | `New-AzStorageAccount`    | `az storage account create`
:---                        | :---                      | :---
Specify custom domain name  | `-CustomDomainName`       | `--custom-domain`
Require HTTPS/SSL           | `-EnableHttpsTrafficOnly` | `--https-only`
Automatically create and assign an identity to manage keys in Azure KeyVault | `AssignIdentity`          | `--assign-identity`

#### Create a storage account (Portal)
Click **Create a resouce**, then **Storage**, then **Storage account**. Choose a **globally** unique name for the account, containing lower-case characters and digits only.

#### Create a storage account (PowerShell)
```powershell
PS C:\> New-AzStorageAccount `
>> -ResourceGroupName RG
>> -Name mystorage112300
>> -SkuName Standard_LRS
>> -Location WestUS
>> -Kind StorageV2
>> -AccessTier Hot
```

#### Create a storage account (CLI)
```bash
$ az storage account create \
> --name $accountName \
> --resource-group $resourceGroup \
> --location $location \
> --sku $sku
```

#### Change storage account's access tier, without confirmation (PowerShell)
```powershell
PS C:\> Set-AzStorageAccount `
>> -ResourceGroupName RG `
>> -Name $accountName `
>> -AccessTier Cool `
>> -Force
```

### 2.1b: Configure network access to the storage account
Storage accounts are managed through __Azure Resource Manager__ and management operations are authenticated and authorized using __Azure Active Directory__. Every storage account service exposes its own Internet-facing endpoint, which must be secured in one of several ways.

The __storage firewall__ controls IP addresses and VNets can access the storage account and applies to all storage account services.

2 steps to configuring service endpoints
  1. Specify `Microsoft.Storage` in the service endpoint settings of the VNet subnet
  1. Configure which VNets can access a particular storage account

Storage accounts support an additional access control applicable only to blob storage. By default, no public read access is enabled for anonymous users, but users with RBAC rights or with the storage account name and key can have access. This can be done through ARM APIs, the Portal, or Azure Storage Explorer. 

### 2.1c: Manage access keys
Access keys grant full access to all data in all services of a storage account and represent the simplest and most powerful control over access. Access keys are typically used by applications for access to Azure storage, either through a __Shared Access Signature (SAS)__ token or directly accessing the storage itself with the name and key.

Access keys can be regenerated using the Portal or CLI tools (`New-AzStorageAccountKey` or `az storage account keys renew`)

#### Create an Azure Key Vault (PowerShell)
```powershell
PS C:\> New-AzKeyVault `
>>  -VaultName vaultName `
>>  -ResourceGroupNAme rgName `
>>  -Location EastUS 
```

#### Create a software managed key in Azure Key Vault (PowerShell)
```powershell
PS C:\> Add-AzKeyVaultKey `
>>  -VaultName vaultName `
>>  -Name keyName `
>>  -Destination 'Software'
```

#### Retrieve a storage account key (PowerShell)
```powershell
PS C:\> $storageKey = Get-AzStorageAccountKey `
>>  -ResourceGrouupName rgName `
>>  -Name storageAccount `
```

#### Convert storage account key to secure string
```powershell
PS C:\> $secretvalue = ConvertTo-SecureString $storageKey[0].Value -AsPlainText -Force
```

#### Set secret value to be used  (PowerShell)
```powershell
PS C:\> $secret = Set-AzKeyVaultSecret `
>>  -VaultName vaultName `
>>  -Name $secretName `
>>  -SecretValue $secretvalue
```

#### Create an Azure Key Vault (Azure CLI)
```bash
$ az keyvault create \
>   --name $vaultName \
>   --resource-group $rgName \
>   --location $location
```

#### Create a software managed key in Azure Key Vault (Azure CLI)
```bash
$ az keyvault key create \
> --vault-name $vaultName \
> --name $keyName \
> --protection "software"
```

#### Set secret value to be used (Azure CLI)
```bash
$ az keyvault secret set \
> --vault-name $vaultName \
> --name $secretName \
> --value $secretValue
```


### 2.1d: Generate a shared access signature
Generate SAS tokens using Storage Explorer or the CLI.

PowerShell commands:
  - `New-AzStorageAccountSASToken`
  - `New-AzStorageBlobSASToken`
  - `New-AzStorageContainerSASToken`
  - `New-AzStorageFileSASToken`
  - `New-AzStorageQueueSASToken`
  - `New-AzStorageShareSASToken`
  - `New-AzStorageTableSASToken`

#### Create a SAS token for a specific storage blob (PowerShell)
```powershell
PS C:\> New-AzStorageBlobSASToken `
>>  -Container $container `
>>  -Blob $blob `
>>  -Permission "rwd" `
>>  -StartTime $startTime `
>>  -ExpiryTime $startTime.AddHours(4) `
>>  -Context $context
```

#### Create a SAS token for a specific storage blob (Azure CLI)
```bash
$ az storage blob generate-sas \
>   --account-name "storageAccount" \
>   --account-key $storageAccountKey \
>   --container-name $container \
>   --name $blobName \
>   --permissions r \
>   --expiry "2019-05-31"
```

### 2.1f: Implement Azure Storage replication
Storage accounts can be moved freely between LRS, GRS, and RA-GRS replication modes. The data will be replicated in the background asynchronously as required. But ZRS works differently, and the data should simply be copied to a new storage account if the replication option needs to be changed.

#### Change replication mode of a storage account
```powershell
PS C:\> Set-AzStorageAccount `
>>  -ResourceGroupName $resourceGroup `
>>  -Name $accountName `
>>  -SkuName $type
```

#### Use async blob copy service to copy a file
`Start-AzStorageBlobCopy` uses these parameters in the following example:
  - `SrcBlob` source filename
  - `SrcContainer` source container
  - `Context` accepts a context object created by `New-AzStorageContext`
  - `DestContainer` destination container
  - `DestBlob` filename of blob on destination storage account: does not have to be the same as source
  - `DestContext` accepts context object created with details of destination storage account, including authentication key

```powershell
PS C:\> $blobCopyState = Start-AzStorageBlobCopy `
>>  -SrcBlob $blobName `
>>  -SrcContainer $srcContainer `
>>  -Context $srcContext `
>>  -DestContainer $destContainer `
>>  -DestBlob $vhdName
>>  -DestContext $destContext
```

##### Get storage account keys
```powershell
PS C:\> $srcStorageKey = Get-AzStorageAccountKey `
>>  -ResourceGroupName $sourceRGName `
>>  -Name $destStorageAccount

PS C:\> $destStorageKey = Get-AzStorageAccountKey `
>>  -ResourceGroupName $destRGName `
>>  -Name $destStorageAccount
```

##### Create storage account context
```powershell
PS C:\> $srcContext = New-AzStorageContext `
>>  -StorageAccountName $srcStorageAccount `
>>  -StorageAccountKey $srcStorageKey.Value[0]

PS C:\> $destContext = New-AzStorageContext `
>>  -StorageAccountName $destStorageAccount `
>>  -StorageAccountKey $destStorageKey.Value[0]
```

##### Create new container in destination account
```powershell
New-AzstorageContainer `
 -Name $destContainer `
 -Context $destContext
```

##### Monitor progress of the async blob copy
```powershell
PS C:\> $copiedBlob | Get-AzStorageBlobCopyState
```

#### Use AzCopy to copy a blob
```cmd
AzCopy \
 /Source:https://sourceblob.blob.core.windows.net/sourcecontainer/ \
 /Dest:https://deststorage.blob.core.windows.net/destcontainer/ \
 /SourceKey:sourcekey \
 /DestKey:destkey \
 /Pattern:disk1.vhd
```

### 2.2: Import and export
### 2.2a: Configure and use Azure blob storage
There can be multiple **containers** within a storage account, and a container can have its own folder structure.

3 types of blob:
  1. **Page blob**
  2. **Block blob**
  3. **Append blob**

> Task: Create a storage container (PowerShell)

#### Create a storage blob (PowerShell)
```powershell
PS C:\> Set-AzStorageBlobContent `
>>  -File $localFile `
>>  -Container $container `
>>  -Blob $blobName
```

#### Create a storage container (Azure CLI)
```bash
$ az storage container create \
>  --account-name $storageaccount \
>  --name $containername \
>  --public-access off
```

#### Create a storage blob (Azure CLI)
```bash
$ az storage blob upload \
>  --container-name $containerName \
>  --account-name $accountName \
>  --account-key $accountKey \
>  --file $file \
>  --name $blobName
```

### Create export from Azure job
### Create import into Azure job
### Use Azure Data Box
3 variations of Data Box:
  - **Data Box Disk**: up to 35 TB and 1 storage account
  - **Data Box**: up to 80 TB and 10 storage accounts
  - **Data Box Heavy**: up to 800 TB and 10 storage accounts
### Configure Azure content delivery network (CDN) endpoints

### 2.3: Configure Azure files
__Azure File Service__ allows you to create one or more file shares in the cloud (up to 5 TB per share), similar to a regular Windows File Server. It supports SMB protocol, so you can connect directly to a file share from outside of Azure, if traffic to port 445 is allowed through the LAN and ISP. It can also be mapped within Windows.

### 2.3a: Using Azure File Service
Use cases:
  - Replace on-premises file servers
  - Easily replicate data on-premises to make it available during lift-and-shift migrations
  - Simply cloud development and management



#### Create an Azure File Share (Portal)
1. Open a standard Azure storage account (not premium)
2. **Files**
3. **+ File Share** button

#### Create an Azure File Share (PowerShell)
```powershell
PS C:\> $storageKey = Get-AzStorageAccountKey
>>  -ResourceGroupName $rgName
>>  -Name $storageAccount

PS C:\> $context = New-AzStorageContext
>>  -StorageAccountName $storageAccount
>>  -StorageAccountKey $storageKey.Value[0]

PS C:\> New-AzStorageShare
>>  -Name $shareName
>>  -Context $context
```

#### Create an Azure File Share (CLI)
```powershell
$ constring=$(az storage account show-connection-string -n $storageAccountName)

$ az storage share create \
>  --name $shareName \
>  --quota 2048 \
>  --connection-string $constring
```

#### Connect to and mount an Azure File Share (Windows File Explorer)
1. Right-click on **This PC**
2. Click **Map Network Drive** option
3. Specify drive letter to be used 
4. Specify folder: `\\<storageAccount>.files.core.windows.net\<shareName>`
5. Click **Finish**
6. In the dialog box that opens login with the username: `AZURE\<storageName>`
7. Password should be access key for the storage account

#### Connect to and mount an Azure File Share (Linux)
Mounting to `/logs`
```bash
sudo mount \
-t cifs //$storageAccount.file.core.windows.net/logs /logs \
-o vers=3.0,username=$storageAccount,password=$storageAccountKey,dir_mode=0777,file_mode=0777,sec=ntlmssp
```

#### Connect to and mount an Azure File Share (net use command)
```cmd
net use x \\erstandard01.file.core.windows.net\logs /u:AZURE\erstandard01 <accessKey>
```

#### Connect to and mount an Azure File Share (PowerShell)
`New-PSDrive` maps the drive
```powershell
PS C:\> $storageKey = (Get-AzStorageAccountKey -ResourceGroupName $rgName -Name $storageNAme).Value[0]
PS C:\> $acctKey = ConvertTo-SecureString -String $storageKey -AsPlainText -Force
PS C:\> $credential = New-Object System.Management.Automation.PSCredential `
>>  -ArgumentList "Azure\$storageName", $acctKey

PS C:\> New-PSDrive `
>>  -Name "Z" `
>>  -PSProvider FileSystem `
>>  -Root "\\$storageName.file.core.windows.net\$shareName" 
>>  -Credential $credential
```

### 2.3b: Create Azure File Sync service

### 2.3c: Create Azure sync group

### 2.3d: Troubleshoot Azure File Sync
